{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa52b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
       "div.output {font-size:14pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:14pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
       "table.dataframe{font-size:14px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
    "div.output {font-size:14pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:14pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
    "table.dataframe{font-size:14px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63e6a2",
   "metadata": {},
   "source": [
    "<b><font size=\"6\" color=\"red\">ch14_웹데이터 수집 - 동적</font></b>\n",
    "# 1절. Selenium을 이용한 동적 웹크롤링 문법\n",
    "- Selenium docs : https://selenium-python.readthedocs.io/\n",
    "`pip install selenium`\n",
    "- import에서 에러날 경우\n",
    "`pip installrequests` 나 `conda install urllib3==1.26.18`로 다운그레이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f8c763",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2025.11.12)\n",
      "Requirement already satisfied: urllib3[socks]<3.0,>=2.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81ced210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c48ae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element(By.NAME, 'q')   # select('input[name=q]') 와 같다\n",
    "elem.clear()\n",
    "elem.send_keys('pycon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f52e432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "elem.send_keys(Keys.RETURN)  # Enter를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e0ca21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_elem = driver.find_element(By.CSS_SELECTOR, 'button#submit')\n",
    "btn_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "177bb5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - https://www.python.org/psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - https://www.python.org/events/python-events/378/\n",
      "PyCon Australia 2013 - https://www.python.org/events/python-events/57/\n",
      "PyCon AU 2019 - https://www.python.org/events/python-events/776/\n",
      "PyCon NL 2025 - https://www.python.org/events/python-events/2084/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/10/\n",
      "PyCon Ireland 2012 - https://www.python.org/events/python-events/76/\n",
      "PyCon Ireland 2016 - https://www.python.org/events/python-events/429/\n",
      "PyCon Ireland 2022 - https://www.python.org/events/python-events/1320/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/1447/\n",
      "PyCon Ireland 2024 - https://www.python.org/events/python-events/1862/\n",
      "PyCon APAC 2025 - https://www.python.org/events/python-events/1879/\n",
      "PyCon AU 2018 - https://www.python.org/events/python-events/696/\n",
      "PyCon APAC 2022 - https://www.python.org/events/python-events/1216/\n",
      "PyCon PH 2024 - https://www.python.org/events/python-events/1661/\n",
      "PyCon Ireland 2023 - https://www.python.org/events/python-events/1568/\n",
      "PyCon PL 2014 - https://www.python.org/events/python-events/191/\n",
      "PyCon MY 2015 - https://www.python.org/events/python-events/313/\n",
      "PyCon Ireland 2015 - https://www.python.org/events/python-events/333/\n",
      "PyCon AU 2015 - https://www.python.org/events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "result_list = driver.find_elements(By.CSS_SELECTOR, 'li > h3 > a')\n",
    "for result in result_list:\n",
    "    title = result.text\n",
    "    link = result.get_attribute('href')\n",
    "    print('{} - {}'.format(title, link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8b169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - /psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - /events/python-events/378/\n",
      "PyCon Australia 2013 - /events/python-events/57/\n",
      "PyCon AU 2019 - /events/python-events/776/\n",
      "PyCon NL 2025 - /events/python-events/2084/\n",
      "PyCon Australia 2014 - /events/python-events/10/\n",
      "PyCon Ireland 2012 - /events/python-events/76/\n",
      "PyCon Ireland 2016 - /events/python-events/429/\n",
      "PyCon Ireland 2022 - /events/python-events/1320/\n",
      "PyCon Australia 2014 - /events/python-events/1447/\n",
      "PyCon Ireland 2024 - /events/python-events/1862/\n",
      "PyCon APAC 2025 - /events/python-events/1879/\n",
      "PyCon AU 2018 - /events/python-events/696/\n",
      "PyCon APAC 2022 - /events/python-events/1216/\n",
      "PyCon PH 2024 - /events/python-events/1661/\n",
      "PyCon Ireland 2023 - /events/python-events/1568/\n",
      "PyCon PL 2014 - /events/python-events/191/\n",
      "PyCon MY 2015 - /events/python-events/313/\n",
      "PyCon Ireland 2015 - /events/python-events/333/\n",
      "PyCon AU 2015 - /events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d1b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/search/?q=pycon&submit=\n",
      "ParseResult(scheme='https', netloc='www.python.org', path='/search/', params='', query='q=pycon&submit=', fragment='')\n",
      "https://www.python.org\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "current_url = driver.current_url  # 셀레니움을 통해 접근한 \n",
    "print(current_url)\n",
    "\n",
    "parse_url = urlparse(current_url)\n",
    "print(parse_url)\n",
    "domain = f'{parse_url.scheme}://{parse_url.netloc}'\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "433498c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - https://www.python.org/psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - https://www.python.org/events/python-events/378/\n",
      "PyCon Australia 2013 - https://www.python.org/events/python-events/57/\n",
      "PyCon AU 2019 - https://www.python.org/events/python-events/776/\n",
      "PyCon NL 2025 - https://www.python.org/events/python-events/2084/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/10/\n",
      "PyCon Ireland 2012 - https://www.python.org/events/python-events/76/\n",
      "PyCon Ireland 2016 - https://www.python.org/events/python-events/429/\n",
      "PyCon Ireland 2022 - https://www.python.org/events/python-events/1320/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/1447/\n",
      "PyCon Ireland 2024 - https://www.python.org/events/python-events/1862/\n",
      "PyCon APAC 2025 - https://www.python.org/events/python-events/1879/\n",
      "PyCon AU 2018 - https://www.python.org/events/python-events/696/\n",
      "PyCon APAC 2022 - https://www.python.org/events/python-events/1216/\n",
      "PyCon PH 2024 - https://www.python.org/events/python-events/1661/\n",
      "PyCon Ireland 2023 - https://www.python.org/events/python-events/1568/\n",
      "PyCon PL 2014 - https://www.python.org/events/python-events/191/\n",
      "PyCon MY 2015 - https://www.python.org/events/python-events/313/\n",
      "PyCon Ireland 2015 - https://www.python.org/events/python-events/333/\n",
      "PyCon AU 2015 - https://www.python.org/events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, domain+result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91dc3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # 브라우저 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9378a9",
   "metadata": {},
   "source": [
    "# 2절. 동적웹크롤링 예제\n",
    "## 2.1 다음뉴스검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73da6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 단어는?비트코인\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "driver.get('http://www.daum.net/')               # 다음페이지로 이동\n",
    "# driver.implicitly_wait(0.5)                    # 브라우저가 열릴때 까지 최대 0.5초 대기\n",
    "time.sleep(0.5)                                  # 0.5초 멈춤\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()  # 클래스가 'tf_keyword'인 요소를 가져와서 클릭해\n",
    "query = input('검색할 단어는?')                             # 사용자로 부터 입력값 받기\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)  # 검색창에 입력값 전달\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()   # 돋보기 아이콘 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb72ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 탭 클릭                         ul.list_tab하위의 li요소들\n",
    "# driver.find_elements(By.CSS_SELECTOR, 'ul.list_tab > li')[1].click()\n",
    "driver.find_element(By.LINK_TEXT, '뉴스').click()    # 링크가 결려있으면서 텍스트가 뉴스인것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2515e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 제목과 link를 list에 추가\n",
    "news_list = []\n",
    "strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "# print(len(strongs))\n",
    "for strong in strongs:\n",
    "    a = strong.find_element(By.TAG_NAME, 'a')\n",
    "    title = a.text\n",
    "    link  = a.get_attribute('href')    #    print(title, link)\n",
    "    news_list.append([title, link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fb4dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5\n"
     ]
    }
   ],
   "source": [
    "# 다음 페이지로  1이면 2, 2이면 3.....\n",
    "page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')  # 페이지 번호요소 가져오기\n",
    "print(page_nav.text)   # 페이지 번호 출력\n",
    "next_page = page_nav.find_element(By.LINK_TEXT, \"2\")  # 링크걸린 텍스트중 2를 가져와\n",
    "next_page.click()    # 2클릭해서 2페이지로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2542781",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5739c",
   "metadata": {},
   "source": [
    "## 2.2 페이징 처리\n",
    "- 다음 뉴스 페이징 처리 : 원하는 keyword를 원하는 페이지만큼 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628828e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 단어는?비트코인\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"美 셧다운 풀리면 XRP 현물 ETF 러시\"…'알트코인 랠리' 올까 [강민승의 알...</td>\n",
       "      <td>http://v.daum.net/v/20251112144248097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>다단계 사기로 갈취한 비트코인만 9조··· 중국인, 英서 ‘중형’[글로벌 왓]</td>\n",
       "      <td>http://v.daum.net/v/20251112103914094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증</td>\n",
       "      <td>http://v.daum.net/v/20251111140546725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "27  \"美 셧다운 풀리면 XRP 현물 ETF 러시\"…'알트코인 랠리' 올까 [강민승의 알...   \n",
       "28        다단계 사기로 갈취한 비트코인만 9조··· 중국인, 英서 ‘중형’[글로벌 왓]   \n",
       "29           비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증   \n",
       "\n",
       "                                     link  \n",
       "27  http://v.daum.net/v/20251112144248097  \n",
       "28  http://v.daum.net/v/20251112103914094  \n",
       "29  http://v.daum.net/v/20251111140546725  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "driver.get('http://www.daum.net/')               # Daum 페이지로 이동\n",
    "# driver.implicitly_wait(0.5)                    # 브라우저가 열릴때 까지 최대 0.5초 대기\n",
    "time.sleep(0.5)                                  # 0.5초 멈춤\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()  # 클래스가 'tf_keyword'인 요소를 가져와서 클릭해\n",
    "query = input('검색할 단어는?')                             # 사용자로 부터 입력값 받기\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)  # 검색창에 입력값 전달\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()   # 돋보기 아이콘 클릭\n",
    "time.sleep(2)\n",
    "# 뉴스탭 이동\n",
    "driver.find_element(By.LINK_TEXT, '뉴스').click() \n",
    "\n",
    "# 뉴스 제목과 link를 list에 추가\n",
    "news_list = []\n",
    "pages = 3   # int(input('몇 페이지 크롤링할까?'))\n",
    "for page in range(1, pages+1):  # 한 페이지당\n",
    "    strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "    # print(len(strongs))\n",
    "    for strong in strongs:     # 10건의 기사\n",
    "        a = strong.find_element(By.TAG_NAME, 'a')\n",
    "        title = a.text\n",
    "        link  = a.get_attribute('href')    #    print(title, link)\n",
    "        news_list.append([title, link])\n",
    "    page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')\n",
    "    next_page = page_nav.find_element(By.LINK_TEXT, str(page+1))\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "driver.close()\n",
    "import pandas as pd\n",
    "pd.DataFrame(news_list, columns=['title','link']).tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7622da8",
   "metadata": {},
   "source": [
    "## 2.3 맞춤법 검사기\n",
    "- 네이버 맞춤법 검사기 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bce1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbc2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 반갑습니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.naver.com/')\n",
    "time.sleep(1)\n",
    "elem = driver.find_element(By.ID,'query')\n",
    "elem.send_keys('맞춤법 검사기')\n",
    "elem.send_keys(Keys.RETURN)   # form태그의 submit 클릭 효과  - 네이버의 검색창에 '맞춤법 검사기' 입력하고 엔터\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME,'txt_gray')\n",
    "textarea.clear()\n",
    "textarea.send_keys('안뇽하세요. 반갑숩니다. 감샤합니다.')  # 맞춤법에 어긋난 문자열 입력\n",
    "btn = driver.find_element(By.CLASS_NAME,'btn_check')  # 검사하기 버튼 가져오기\n",
    "btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 결과 가져오기   'p._result_text stand_txt'\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result = soup.select_one('p._result_text.stand_txt').text\n",
    "print(result)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb22d15",
   "metadata": {},
   "source": [
    "- 맞춤법검사전.txt 읽어서 300자 단위로 짤라 list에 넣어 동적웹크롤링을 한후, 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01bcc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['거북이는 파충류에 속하는 동물로, 등딱지와 배딱지로 이루어진 단단한 껍질이 몸을 보후하는 것이 가장 큰 특징우다. 전 세계적으로 약 300여 종이 알려져 있으며, 육지, 바다, 강과 같은 다양한 환경에서 서식한다. 육지에 사는 거북이는 주로 식물성 먹이를 먹고, 바다거북은 해조류나 해양 무척추동물을 섭취한다. 거북이는 폐로 호흡하며, 변온동물이기 때문에 주위 온도에 따라 체온이 변한댜. 그래서 햇빛을 쬐며 체온을 조절하는 모습을 자주 볼 수 있다.\\n', '거북이의 번식 방식은 알을 낳는 난생으로, 암컷은 나뭇잎이나 모래 속에 알을 낳고 부화할 때까지 보호하지 않는디. 알은 자연의 온도에 따라 부화 시 암수 비율이 달라지는 독특한 특징을 가진다. 거북이는 수명이 매우 길어 종에 따라 수십 년에서 100년 이상 살기도 한다. 예를 들어, 갈라파고스 거북은 150년 이상 생존하는 것으로 알려져 있다.\\n', '오랜 세월 동안 거북이는 느리지만 꾸준한 상징으로 여겨졌으며, 여러 문화권에서 지혜와 장수를 의미했더. 그러나 최근 서식지 파괴와 불법 포획, 플라스틱 오염 등으로 많은 종이 멸종 위기에 처해 있다. 바다거북의 경우 해안 개발로 산란지가 줄고, 해양 쓰레기를 먹이로 오인해 생명을 위협받는 일이 많다. 이러한 문제를 해결하기 위해 각국에서는 보호구역을 지정하구, 부화장을 운영하는 등 보존 노력을 이어가고 있다.']\n",
      "[253, 194, 230]\n",
      "253\n",
      "194\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "with open('data/ch14_맞춤법검사전1.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "ready_text = []  # 300자씩 나눠진 text\n",
    "while(len(text)>300):\n",
    "    temp = text[:300]\n",
    "    last_dot_index = temp.rfind('\\n')\n",
    "    ready_text.append(text[:last_dot_index])\n",
    "    text = text[last_dot_index+1 : ]\n",
    "ready_text.append(text)\n",
    "print(ready_text)\n",
    "print([len(ready) for ready in ready_text])\n",
    "for ready in ready_text:\n",
    "    print(len(ready))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee5a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검사중...1/3\n",
      "검사중...2/3\n",
      "검사중...3/3\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "time.sleep(1)\n",
    "driver.get('https://www.naver.com/')\n",
    "time.sleep(1)\n",
    "elem = driver.find_element(By.ID,'query')\n",
    "elem.send_keys('맞춤법 검사기')\n",
    "elem.send_keys(Keys.RETURN)   # form태그의 submit 클릭 효과  - 네이버의 검색창에 '맞춤법 검사기' 입력하고 엔터\n",
    "time.sleep(1)\n",
    "textarea = driver.find_element(By.CLASS_NAME,'txt_gray')\n",
    "results = ''  # 맞춤법 검사 완료된 text\n",
    "for i, ready in enumerate(ready_text):\n",
    "    print(f'검사중...{i+1}/{len(ready_text)}')\n",
    "    # textarea.clear()   # 첫번째 요소 지우고\n",
    "    textarea.send_keys(Keys.CONTROL,'a')   # ctrl+a  - 전체선택 (비추)\n",
    "    textarea.send_keys(ready)\n",
    "    time.sleep(1)\n",
    "    btn = driver.find_element(By.CLASS_NAME,'btn_check')  # 검사하기 버튼 가져오기\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.select_one('p._result_text.stand_txt').text\n",
    "    if '검사가 불가능합니다' in result :\n",
    "        result += ready + '\\n'\n",
    "    else:\n",
    "        results += result + '\\n'\n",
    "#     results += result + '\\n'\n",
    "    time.sleep(1)\n",
    "# driver.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c6c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맞춤법 검사 결과를 파일로 출력\n",
    "with open('data/ch14_맞춤법검사후1.txt', 'w',encoding='utf-8') as f:\n",
    "    f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600db258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료됨\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "with open('data/ch14_맞춤법검사후1.txt','r',encoding='utf-8') as f:\n",
    "    ready_text = f.read()\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "time.sleep(1)\n",
    "driver.get('https://papago.naver.com/')\n",
    "results = ''  # 번역 완료된 text\n",
    "textarea = driver.find_element(By.ID,'txtSource')\n",
    "btn = driver.find_element(By.ID,'btnTranslate')  # 번역하기 버튼 가져오기\n",
    "textarea.send_keys(ready_text)\n",
    "btn.click()\n",
    "time.sleep(2)\n",
    "result = driver.find_element(By.CSS_SELECTOR, 'div#txtTarget').text\n",
    "# soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# result = soup.select_one('div#txtTarget').text\n",
    "driver.close()\n",
    "# 번역 후 결과를 파일로 출력\n",
    "with open('data/ch14_번역후1.txt', 'w',encoding='utf-8') as f:\n",
    "    f.write(result)\n",
    "print('완료됨')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1f508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69b9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178ea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20e5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
