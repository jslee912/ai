{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa52b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
       "div.output {font-size:14pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:14pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
       "table.dataframe{font-size:14px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
    "div.output {font-size:14pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:14pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
    "table.dataframe{font-size:14px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63e6a2",
   "metadata": {},
   "source": [
    "<b><font size=\"6\" color=\"red\">ch14_웹데이터 수집 - 동적</font></b>\n",
    "# 1절. Selenium을 이용한 동적 웹크롤링 문법\n",
    "- Selenium docs : https://selenium-python.readthedocs.io/\n",
    "`pip install selenium`\n",
    "- import에서 에러날 경우\n",
    "`pip installrequests` 나 `conda install urllib3==1.26.18`로 다운그레이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f8c763",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2025.11.12)\n",
      "Requirement already satisfied: urllib3[socks]<3.0,>=2.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81ced210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c48ae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element(By.NAME, 'q')   # select('input[name=q]') 와 같다\n",
    "elem.clear()\n",
    "elem.send_keys('pycon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f52e432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "elem.send_keys(Keys.RETURN)  # Enter를 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e0ca21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_elem = driver.find_element(By.CSS_SELECTOR, 'button#submit')\n",
    "btn_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "177bb5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - https://www.python.org/psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - https://www.python.org/events/python-events/378/\n",
      "PyCon Australia 2013 - https://www.python.org/events/python-events/57/\n",
      "PyCon AU 2019 - https://www.python.org/events/python-events/776/\n",
      "PyCon NL 2025 - https://www.python.org/events/python-events/2084/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/10/\n",
      "PyCon Ireland 2012 - https://www.python.org/events/python-events/76/\n",
      "PyCon Ireland 2016 - https://www.python.org/events/python-events/429/\n",
      "PyCon Ireland 2022 - https://www.python.org/events/python-events/1320/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/1447/\n",
      "PyCon Ireland 2024 - https://www.python.org/events/python-events/1862/\n",
      "PyCon APAC 2025 - https://www.python.org/events/python-events/1879/\n",
      "PyCon AU 2018 - https://www.python.org/events/python-events/696/\n",
      "PyCon APAC 2022 - https://www.python.org/events/python-events/1216/\n",
      "PyCon PH 2024 - https://www.python.org/events/python-events/1661/\n",
      "PyCon Ireland 2023 - https://www.python.org/events/python-events/1568/\n",
      "PyCon PL 2014 - https://www.python.org/events/python-events/191/\n",
      "PyCon MY 2015 - https://www.python.org/events/python-events/313/\n",
      "PyCon Ireland 2015 - https://www.python.org/events/python-events/333/\n",
      "PyCon AU 2015 - https://www.python.org/events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "result_list = driver.find_elements(By.CSS_SELECTOR, 'li > h3 > a')\n",
    "for result in result_list:\n",
    "    title = result.text\n",
    "    link = result.get_attribute('href')\n",
    "    print('{} - {}'.format(title, link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8b169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - /psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - /events/python-events/378/\n",
      "PyCon Australia 2013 - /events/python-events/57/\n",
      "PyCon AU 2019 - /events/python-events/776/\n",
      "PyCon NL 2025 - /events/python-events/2084/\n",
      "PyCon Australia 2014 - /events/python-events/10/\n",
      "PyCon Ireland 2012 - /events/python-events/76/\n",
      "PyCon Ireland 2016 - /events/python-events/429/\n",
      "PyCon Ireland 2022 - /events/python-events/1320/\n",
      "PyCon Australia 2014 - /events/python-events/1447/\n",
      "PyCon Ireland 2024 - /events/python-events/1862/\n",
      "PyCon APAC 2025 - /events/python-events/1879/\n",
      "PyCon AU 2018 - /events/python-events/696/\n",
      "PyCon APAC 2022 - /events/python-events/1216/\n",
      "PyCon PH 2024 - /events/python-events/1661/\n",
      "PyCon Ireland 2023 - /events/python-events/1568/\n",
      "PyCon PL 2014 - /events/python-events/191/\n",
      "PyCon MY 2015 - /events/python-events/313/\n",
      "PyCon Ireland 2015 - /events/python-events/333/\n",
      "PyCon AU 2015 - /events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d1b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/search/?q=pycon&submit=\n",
      "ParseResult(scheme='https', netloc='www.python.org', path='/search/', params='', query='q=pycon&submit=', fragment='')\n",
      "https://www.python.org\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "current_url = driver.current_url  # 셀레니움을 통해 접근한 \n",
    "print(current_url)\n",
    "\n",
    "parse_url = urlparse(current_url)\n",
    "print(parse_url)\n",
    "domain = f'{parse_url.scheme}://{parse_url.netloc}'\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "433498c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSF PyCon Trademark Usage Policy - https://www.python.org/psf/trademarks/pycon\n",
      "PyCon Italia 2016 (PyCon Sette) - https://www.python.org/events/python-events/378/\n",
      "PyCon Australia 2013 - https://www.python.org/events/python-events/57/\n",
      "PyCon AU 2019 - https://www.python.org/events/python-events/776/\n",
      "PyCon NL 2025 - https://www.python.org/events/python-events/2084/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/10/\n",
      "PyCon Ireland 2012 - https://www.python.org/events/python-events/76/\n",
      "PyCon Ireland 2016 - https://www.python.org/events/python-events/429/\n",
      "PyCon Ireland 2022 - https://www.python.org/events/python-events/1320/\n",
      "PyCon Australia 2014 - https://www.python.org/events/python-events/1447/\n",
      "PyCon Ireland 2024 - https://www.python.org/events/python-events/1862/\n",
      "PyCon APAC 2025 - https://www.python.org/events/python-events/1879/\n",
      "PyCon AU 2018 - https://www.python.org/events/python-events/696/\n",
      "PyCon APAC 2022 - https://www.python.org/events/python-events/1216/\n",
      "PyCon PH 2024 - https://www.python.org/events/python-events/1661/\n",
      "PyCon Ireland 2023 - https://www.python.org/events/python-events/1568/\n",
      "PyCon PL 2014 - https://www.python.org/events/python-events/191/\n",
      "PyCon MY 2015 - https://www.python.org/events/python-events/313/\n",
      "PyCon Ireland 2015 - https://www.python.org/events/python-events/333/\n",
      "PyCon AU 2015 - https://www.python.org/events/python-events/273/\n"
     ]
    }
   ],
   "source": [
    "result_list = soup.select('li > h3 > a')\n",
    "for result in result_list:\n",
    "    print(\"{} - {}\".format(result.text, domain+result.attrs['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91dc3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()  # 브라우저 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9378a9",
   "metadata": {},
   "source": [
    "# 2절. 동적웹크롤링 예제\n",
    "## 2.1 다음뉴스검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73da6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 단어는?비트코인\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "driver.get('http://www.daum.net/')               # 다음페이지로 이동\n",
    "# driver.implicitly_wait(0.5)                    # 브라우저가 열릴때 까지 최대 0.5초 대기\n",
    "time.sleep(0.5)                                  # 0.5초 멈춤\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()  # 클래스가 'tf_keyword'인 요소를 가져와서 클릭해\n",
    "query = input('검색할 단어는?')                             # 사용자로 부터 입력값 받기\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)  # 검색창에 입력값 전달\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()   # 돋보기 아이콘 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb72ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 탭 클릭                         ul.list_tab하위의 li요소들\n",
    "# driver.find_elements(By.CSS_SELECTOR, 'ul.list_tab > li')[1].click()\n",
    "driver.find_element(By.LINK_TEXT, '뉴스').click()    # 링크가 결려있으면서 텍스트가 뉴스인것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2515e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 제목과 link를 list에 추가\n",
    "news_list = []\n",
    "strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "# print(len(strongs))\n",
    "for strong in strongs:\n",
    "    a = strong.find_element(By.TAG_NAME, 'a')\n",
    "    title = a.text\n",
    "    link  = a.get_attribute('href')    #    print(title, link)\n",
    "    news_list.append([title, link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fb4dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5\n"
     ]
    }
   ],
   "source": [
    "# 다음 페이지로  1이면 2, 2이면 3.....\n",
    "page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')  # 페이지 번호요소 가져오기\n",
    "print(page_nav.text)   # 페이지 번호 출력\n",
    "next_page = page_nav.find_element(By.LINK_TEXT, \"2\")  # 링크걸린 텍스트중 2를 가져와\n",
    "next_page.click()    # 2클릭해서 2페이지로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2542781",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5739c",
   "metadata": {},
   "source": [
    "## 2.2 페이징 처리\n",
    "- 다음 뉴스 페이징 처리 : 원하는 keyword를 원하는 페이지만큼 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628828e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 단어는?비트코인\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"美 셧다운 풀리면 XRP 현물 ETF 러시\"…'알트코인 랠리' 올까 [강민승의 알...</td>\n",
       "      <td>http://v.daum.net/v/20251112144248097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>다단계 사기로 갈취한 비트코인만 9조··· 중국인, 英서 ‘중형’[글로벌 왓]</td>\n",
       "      <td>http://v.daum.net/v/20251112103914094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증</td>\n",
       "      <td>http://v.daum.net/v/20251111140546725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "27  \"美 셧다운 풀리면 XRP 현물 ETF 러시\"…'알트코인 랠리' 올까 [강민승의 알...   \n",
       "28        다단계 사기로 갈취한 비트코인만 9조··· 중국인, 英서 ‘중형’[글로벌 왓]   \n",
       "29           비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증   \n",
       "\n",
       "                                     link  \n",
       "27  http://v.daum.net/v/20251112144248097  \n",
       "28  http://v.daum.net/v/20251112103914094  \n",
       "29  http://v.daum.net/v/20251111140546725  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "driver.get('http://www.daum.net/')               # Daum 페이지로 이동\n",
    "# driver.implicitly_wait(0.5)                    # 브라우저가 열릴때 까지 최대 0.5초 대기\n",
    "time.sleep(0.5)                                  # 0.5초 멈춤\n",
    "driver.find_element(By.CLASS_NAME, 'tf_keyword').click()  # 클래스가 'tf_keyword'인 요소를 가져와서 클릭해\n",
    "query = input('검색할 단어는?')                             # 사용자로 부터 입력값 받기\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[type=\"text\"]').send_keys(query)  # 검색창에 입력값 전달\n",
    "driver.find_element(By.CLASS_NAME, 'btn_ksearch').click()   # 돋보기 아이콘 클릭\n",
    "time.sleep(2)\n",
    "# 뉴스탭 이동\n",
    "driver.find_element(By.LINK_TEXT, '뉴스').click() \n",
    "\n",
    "# 뉴스 제목과 link를 list에 추가\n",
    "news_list = []\n",
    "pages = 3   # int(input('몇 페이지 크롤링할까?'))\n",
    "for page in range(1, pages+1):  # 한 페이지당\n",
    "    strongs = driver.find_elements(By.CSS_SELECTOR, 'div.item-title > strong')\n",
    "    # print(len(strongs))\n",
    "    for strong in strongs:     # 10건의 기사\n",
    "        a = strong.find_element(By.TAG_NAME, 'a')\n",
    "        title = a.text\n",
    "        link  = a.get_attribute('href')    #    print(title, link)\n",
    "        news_list.append([title, link])\n",
    "    page_nav = driver.find_element(By.CSS_SELECTOR, 'div.inner_paging')\n",
    "    next_page = page_nav.find_element(By.LINK_TEXT, str(page+1))\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "driver.close()\n",
    "import pandas as pd\n",
    "pd.DataFrame(news_list, columns=['title','link']).tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7622da8",
   "metadata": {},
   "source": [
    "## 2.3 맞춤법 검사기\n",
    "- 네이버 맞춤법 검사기 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bce1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbc2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 반갑습니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.naver.com/')\n",
    "time.sleep(1)\n",
    "elem = driver.find_element(By.ID,'query')\n",
    "elem.send_keys('맞춤법 검사기')\n",
    "elem.send_keys(Keys.RETURN)   # form태그의 submit 클릭 효과  - 네이버의 검색창에 '맞춤법 검사기' 입력하고 엔터\n",
    "\n",
    "textarea = driver.find_element(By.CLASS_NAME,'txt_gray')\n",
    "textarea.clear()\n",
    "textarea.send_keys('안뇽하세요. 반갑숩니다. 감샤합니다.')  # 맞춤법에 어긋난 문자열 입력\n",
    "btn = driver.find_element(By.CLASS_NAME,'btn_check')  # 검사하기 버튼 가져오기\n",
    "btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 결과 가져오기   'p._result_text stand_txt'\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result = soup.select_one('p._result_text.stand_txt').text\n",
    "print(result)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb22d15",
   "metadata": {},
   "source": [
    "- 맞춤법검사전.txt 읽어서 300자 단위로 짤라 list에 넣어 동적웹크롤링을 한후, 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01bcc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안뇽하세요\\n윤석열은 한국 정치에서 독특한 궤적을 걸어온 인물이댜. 검사로서 긴 세월을 보냈고, 정의와 원칙을 중시하는 강직한 성격으로 알려졌으다냐. 거칠고 직설적인 언행 때문에 때로는 논란의 중심에 서기도 했지만, 그런 솔직함이 오히려 대중에게 신선하게 다가오기도 했뎌. 검찰총장에서 대통령으로, 그리고 다시 정치인으로 남은 그의 행보는 한국 현대 정치의 굴곡을 고스란히 보여준댜.\\n', '윤석열의 이미지는 한편으로는 단단하고, 다른 한편으로는 인간적이냐냐냐다. 개와 고양이를 사랑하고, 아내와의 일화를 나누는 모습에서 그는 의외의 따뜻함을 드러낸다. 정치의 소용돌이 속에서도 그는 흔들림 없는 눈빛으로 자신의 길을 가려 했다. 찬반은 엇갈리지만, 그의 존재가 한국 사회의 다양한 목소리를 이끌어낸 것은 분명하다. 윤석열이라는 이름은 앞으로도 한국 정치의 한 페이지에 또렷하게 남을 것이다.']\n",
      "[214, 224]\n",
      "214\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "with open('data/ch14_맞춤법검사전.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "ready_text = []  # 300자씩 나눠진 text\n",
    "while(len(text)>300):\n",
    "    temp = text[:300]\n",
    "    last_dot_index = temp.rfind('\\n')\n",
    "    ready_text.append(text[:last_dot_index])\n",
    "    text = text[last_dot_index+1 : ]\n",
    "ready_text.append(text)\n",
    "print(ready_text)\n",
    "print([len(ready) for ready in ready_text])\n",
    "for ready in ready_text:\n",
    "    print(len(ready))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee5a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검사중...1/2\n",
      "검사중...2/2\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver                   # 브라우저 열기를 위해\n",
    "from selenium.webdriver.common.by import By      # 요소선택\n",
    "from selenium.webdriver.common.keys import Keys  # 키보드입력\n",
    "import time                                      # 프로세스 중지를 위해 - 1초 기다리기, 뜰대까지 기다리기\n",
    "driver = webdriver.Chrome()                      # 브라우저 띄우기\n",
    "time.sleep(1)\n",
    "driver.get('https://www.naver.com/')\n",
    "time.sleep(1)\n",
    "elem = driver.find_element(By.ID,'query')\n",
    "elem.send_keys('맞춤법 검사기')\n",
    "elem.send_keys(Keys.RETURN)   # form태그의 submit 클릭 효과  - 네이버의 검색창에 '맞춤법 검사기' 입력하고 엔터\n",
    "time.sleep(1)\n",
    "textarea = driver.find_element(By.CLASS_NAME,'txt_gray')\n",
    "results = ''  # 맞춤법 검사 완료된 text\n",
    "for i, ready in enumerate(ready_text):\n",
    "    print(f'검사중...{i+1}/{len(ready_text)}')\n",
    "    # textarea.clear()   # 첫번째 요소 지우고\n",
    "    textarea.send_keys(Keys.CONTROL,'a')   # ctrl+a  - 전체선택 (비추)\n",
    "    textarea.send_keys(ready)\n",
    "    time.sleep(1)\n",
    "    btn = driver.find_element(By.CLASS_NAME,'btn_check')  # 검사하기 버튼 가져오기\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.select_one('p._result_text.stand_txt').text\n",
    "    results += result + '\\n'\n",
    "    time.sleep(1)\n",
    "# driver.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c6c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맞춤법 검사 결과를 파일로 출력\n",
    "with open('data/ch14_맞춤법검사후.txt', 'w',encoding='utf-8') as f:\n",
    "    f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600db258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1f508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69b9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178ea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20e5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
