{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d23756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
       "div.text_cell_render.rendered_html{font-size:14pt;}\n",
       "div.text_cell_render ul li, code{font-size:22pt; line-height:14px;}\n",
       "div.output {font-size:14pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:14pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
       "table.dataframe{font-size:14px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:14pt;}\n",
    "div.text_cell_render.rendered_html{font-size:14pt;}\n",
    "div.text_cell_render ul li, code{font-size:22pt; line-height:14px;}\n",
    "div.output {font-size:14pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:14pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:14pt;padding:5px;}\n",
    "table.dataframe{font-size:14px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4b67d",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1_허깅페이스</span>\n",
    "- Inference API 이용 : 모델의 결과를 server에서\n",
    "- pipline() 이용 : 모델을 다운로드 받아 모델의 결과를 local에서\n",
    "\n",
    "    * raw text -> tokenizer -> model -> [0.11, 0.55, 0.xx,~]  logits값으로 prediction 결과 출력\n",
    "    \n",
    "```\n",
    "\n",
    "허깅페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-clssification\"의 별칭(감정분석 전용으로 사용)\n",
    "\"text-clssification\" : 감정분석, 뉴스분료, 리뷰 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-clssification\" : 레이블 없이 학습, 주어진 후보군 중에서 분류\n",
    "\"token-clssification\" : 개체명 인식(NER:Named Entity REcognition)등 단위 라벨링\n",
    "\"ner\" : \"token-clssification\" 의 별칭\n",
    "\"fill-mask\" : 빈칸 채우기\n",
    "\"text-generation\" : 텍스트 생성(GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약 등 입력 -> 출력 변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트 요약\n",
    "\"question-answering\" : 주어진 context를 보고 질문에 답하기.\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\" : 이미지 분류\n",
    "\n",
    "```\n",
    "\n",
    "## 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "\n",
    "- C:\\사용자\\내컴퓨터명\\.cache\\huggingface\\hub 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6603f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f631adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"text-classification\",\n",
    "                     model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 감정분석시 내용이 많으면 list로\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f94faeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.857815682888031},\n",
       " {'label': 'POSITIVE', 'score': 0.9998821020126343}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\",\n",
    "            \"This movie was the best. It's touching, and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3333dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8577604293823242}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 물건 정말 사고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849f1bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'POSITIVE', 'score': 0.999488353729248},\n",
       " {'label': 'NEGATIVE', 'score': 0.599323034286499},\n",
       " {'label': 'POSITIVE', 'score': 0.8669533729553223}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I like you\", \"I hat you\", \"나 너가 싫어\", \"힘들어요\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db228b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"text-classification\",\n",
    "                      model=\"matthewburke/korean_sentiment\")\n",
    "texts = ['나는 너가 좋아', \"당신이 싫어요\", \"힘들어요\", \"오늘 기분이 최고야\"]\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ef9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9557897448539734},\n",
       " {'label': 'LABEL_0', 'score': 0.9092598557472229},\n",
       " {'label': 'LABEL_0', 'score': 0.9140233397483826},\n",
       " {'label': 'LABEL_1', 'score': 0.9714491367340088}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e8a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 => 긍정 : 0.9558\n",
      "당신이 싫어요 => 부정 : 0.9093\n",
      "힘들어요 => 부정 : 0.9140\n",
      "오늘 기분이 최고야 => 긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = \"긍정\" if result['label']=='LABEL_1' else \"부정\"\n",
    "    print(f\"{text} => {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10018f4",
   "metadata": {},
   "source": [
    "## 2. 제로샷분류(zero-shot분류)\n",
    "- 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육없이 작업을 수행할 수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c745a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227580070495605,\n",
       "  0.45814019441604614,\n",
       "  0.0142647260800004,\n",
       "  0.0026850001886487007,\n",
       "  0.002152054337784648]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     # model=\"facebook/bart-large-mnli\"\n",
    "                     )\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ce9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9941016435623169, 0.0031261250842362642, 0.0027722232043743134]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"One day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9f761",
   "metadata": {},
   "source": [
    "## 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06df3d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to be a good writer, a good historian, a good historian, a good journalist, a good historian, and you will learn how to be a good teacher.\\n\\nBy the end of this course, you will have read over 60 books, written more than 500 articles, and written more than 250 articles for the New York Times. You will also have written over 1,500 books, more than 300 articles, and written over 2,000 articles for The New York Times.\\n\\nYou will have listened to over 3 million people in more than 40 languages. You will have studied over 3 million books. You will have learned over 2,000 languages. You will have written over 5,000 books. You will have contributed over 600 articles, more than 800 articles, and contributed over 400 articles for The New York Times.\\n\\nYou will have written over 100 articles. You will have written over 600 articles. You will have contributed over 600 articles. You will have a strong interest in history, in the history of the world, in the history of the English language, in the history of the Russian and French languages, in the history of the English language, in the history of the German language, in the history of the Italian language, in the history of the French'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "# set_seed(2)\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스없음\n",
    "generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") # pad_token_id 경고를 없애려고 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aa23c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to make my both in the show. She's against the both in the show. Achievement of these curse both in the football what the curse both in the curse both in the show. She's against the curse both in the curse both in the show. Achievement of the curse both in the curse both in the show.\n",
      "She's against the curse both in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the show in the curse both in the show in the show in the s\n"
     ]
    }
   ],
   "source": [
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") \n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00612113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 한 해리기국 않누 이스현들는아로 지버 기상스현들는 타를 가키는 기상난 해스현들는 무는 기상난 해스현들는 무는 해스현들는 아타마 해스현들는 않맘를 같은 나목환들는 아타마 해스현들는 기상난 해스�\n"
     ]
    }
   ],
   "source": [
    "# generation = pipeline(\"text-generation\", \"gpt2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538982ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. __\"\n",
      "우리는 어느 한 쪽이 자신의 의견을 표명했다고 가정해서 그 결정이 잘못된 것으로 결론지어질 수 있다는 사실을 미리 알고 있어야 한다.\n",
      "어떤 결정이 옳을지라도 그 결정을 실행하기가 더욱 힘들 것이라는 것을 의미한다.\n",
      "이때는 반드시 자신이 결정을 내리기 전에 먼저 상대방의 의사를 들은 다음 그 이유를 설명해주는 것이 좋다.\n",
      "이렇게 해야 자기 의견의 타당성과 실현 가능성에 대해 확신을 갖게 되는 것이다.\n",
      "다른 사람이 내 의견에 찬성하는 것은 자신이 내린 결정의 타당성을 확신할 수 있기 때문이다.\n",
      "그런데 이 방법이 사실 옳은 것이 아닌가?\n",
      "왜냐하면 상대방의 의견을 받아들인 후에 자신의 생각을 다시 진지하게 들으면서 상대방의 주장을 다시 듣는다면 이러한 과정을 통해 자신의 주장이 타당함을 알 수 있다고 보기 때문이다.\n",
      "또한 그 반대의 경우도 마찬가지이다\n",
      "모든 결정을 내린 사람들은 결정을 내리는 데 있어서 자신의 의견은 옳다고 생각한다.\n",
      "그들은 자신이 정한 의견을 반드시 받아들여야만 한다.\n",
      "우리는 결정을 내려면 여러 가지 다른 방법을 생각할 수 있다.\n",
      "그럼에도 불구하고 그들은 결정을 내리려고 노력하지는 않는다.\n",
      "모든 결정은 반드시 그 의견과 다른 의견을 가진 사람만을\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generation = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id,\n",
    "    max_new_tokens = 200, # 생성할 최대 길이 (생성할 토큰 수)\n",
    "    num_return_sequences=1, # 생성할 문장 갯수\n",
    "    do_sample=True,   # 다양한 샘플 사용\n",
    "    top_k=50,         # top-k 샘플링(확률 높은 상위 50개 토큰만 사용)\n",
    "    top_p=0.95,       # 확률이 높은 순서대로 95%가 될 때까지의 단어들로만 후보로 사용\n",
    "    temperature=1.0,  # 창의성 조절(낮을 수록 보수적)\n",
    "    no_repeat_ngram_size=2  # 반복 방지\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffe4e7",
   "metadata": {},
   "source": [
    "## 4. 마스크(빈칸) 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100490d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275707006454468,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794589757919312,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask',\n",
    "                   model='distilbert/distilroberta-base')  # 마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\", top_k=2)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23395a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmasker(\"병원에 가서 <mask>를 만날거예요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfc67f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0629730075597763,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model.\"},\n",
       " {'score': 0.038101598620414734,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model.\"},\n",
       " {'score': 0.03764132782816887,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': \"Hello, I'm a role model.\"},\n",
       " {'score': 0.037326786667108536,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello, I'm a fashion model.\"},\n",
       " {'score': 0.026023676618933678,\n",
       "  'token': 24526,\n",
       "  'token_str': ' Playboy',\n",
       "  'sequence': \"Hello, I'm a Playboy model.\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb47c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2771560847759247,\n",
       "  'token': 6,\n",
       "  'token_str': ',',\n",
       "  'sequence': '안녕, 나는, 모델이에요.'},\n",
       " {'score': 0.10971927642822266,\n",
       "  'token': 35,\n",
       "  'token_str': ':',\n",
       "  'sequence': '안녕, 나는: 모델이에요.'},\n",
       " {'score': 0.1012372151017189,\n",
       "  'token': 126,\n",
       "  'token_str': ' –',\n",
       "  'sequence': '안녕, 나는 – 모델이에요.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"안녕, 나는 <mask> 모델이에요.\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bc954d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4c31d7b35b4a4481b594dca243c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e62103feb264f1eb3dd9c5d4798a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216f7f66cf9d4a7abe37c42cf82de63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bc09b19c554a1297e207377c289412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9941c695104f6599e093da96187d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.06705848127603531,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model\"},\n",
       " {'score': 0.05897250398993492,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask',\n",
    "                   model='google-bert/bert-base-uncased')  # 마스크 채우기\n",
    "unmasker(\"Hello, I'm a [MASK] model\", top_k=2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d905d6e",
   "metadata": {},
   "source": [
    "### ※ Inference API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "816ed79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.environ['HF_TOKEN']\n",
    "# 허깅페이스 토큰을 read권한으로 생성하여 .env에 추가(.gitignore파일도 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c8888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b4346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17e754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379228f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec213f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e704e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28497d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279adca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed01ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b38c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb8603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d9316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd683c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40f336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
